{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv10 + Weights & Biases (W&B) - Custom Dataset Training\n",
        "\n",
        "This notebook demonstrates how to train a YOLOv10 model on a custom dataset using Weights & Biases (W&B) for experiment tracking. The dataset is imported from Roboflow and used in combination with YOLOv10 to detect objects relevant to your project.\n",
        "\n",
        "We also perform a grid search over multiple hyperparameters (model version, batch size, epochs, optimizer) to find the best configuration for training. After training, we can visualize the results (e.g., loss, mAP, precision, recall) directly in Weights & Biases for analysis and comparison.\n",
        "\n",
        "---\n",
        "\n",
        "**Author**: Agus Darmawan  \n",
        "**GitHub**: [github.com/agus-darmawan](https://github.com/agus-darmawan)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check GPU Availability\n",
        "\n",
        "Before starting, we check if a GPU is available for training. This is crucial for optimizing training speed and performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["!nvidia-smi"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize Project Directory\n",
        "\n",
        "We set up the main working directory for our YOLOv10 project. This includes creating a directory for datasets if it doesn't already exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "HOME = Path.cwd() / \"yolov10\"\n",
        "DATASETS_PATH = HOME / \"datasets\"\n",
        "DATASETS_PATH.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"ðŸ“ Project directory: {HOME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utility: Install Required Dependencies\n",
        "\n",
        "This utility function checks if a package is installed, and if not, installs it using pip. This ensures that all necessary packages are available for the notebook to run smoothly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, subprocess, importlib\n",
        "def ensure_package_installed(package_name, import_name=None, version_spec=\"\"):\n",
        "    import_name = import_name or package_name\n",
        "    try:\n",
        "        importlib.import_module(import_name)\n",
        "        print(f\"âœ… {import_name} is already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"âŒ {import_name} not found. Installing...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"{package_name}{version_spec}\"])\n",
        "        print(f\"âœ… {package_name} installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install and Verify YOLOv10\n",
        "\n",
        "We install the YOLOv10 package and verify the installation by checking the version. This ensures that we are using the correct version of YOLOv10 for our training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ensure_package_installed(\"ultralytics\", version_spec=\">=10,<11\")\n",
        "from ultralytics import YOLO\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: Test Initial Inference\n",
        "\n",
        "We can run a quick inference test using a sample image to ensure that YOLOv10 is working correctly. This step is optional but recommended to confirm the installation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model=yolov10n.pt conf=0.25 source='/img/tes.jpg' save=True\n",
        "display(Image(filename='runs/detect/predict/tes.jpg', height=600))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup Roboflow API & Environment Variables\n",
        "\n",
        "We set up the Roboflow API key and load it from an environment variable. This key is essential for accessing datasets hosted on Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ensure_package_installed(\"python-dotenv\", \"dotenv\")\n",
        "ensure_package_installed(\"roboflow\")\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from roboflow import Roboflow\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"ROBOFLOW_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"âŒ API key not found. Ensure .env file contains ROBOFLOW_API_KEY.\")\n",
        "print(\"âœ… API key loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download Dataset from Roboflow\n",
        "\n",
        "We download the dataset from Roboflow using the API key. This step fetches the dataset and prepares it for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(DATASETS_PATH)\n",
        "\n",
        "rf = Roboflow(api_key=api_key)\n",
        "project = rf.workspace(\"agus-darmawan\").project(\"subtantion-monitoring\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Weights & Biases (W&B)\n",
        "\n",
        "Weights & Biases (W&B) is a powerful tool for experiment tracking and visualization. We will set up W&B to log our training metrics and hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ensure_package_installed(\"wandb\")\n",
        "ensure_package_installed(\"torch\")\n",
        "\n",
        "import wandb\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Function with W&B Logging\n",
        "\n",
        "This function encapsulates the training process with YOLOv10 and logs all relevant metrics and hyperparameters to Weights & Biases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_yolo_with_wandb(version, epoch, batch_size, optimizer, dataset_location):\n",
        "    base_dir = HOME / f\"experiments/yolov10{version}\"\n",
        "    experiment_name = f\"epoch_{epoch}_batch_{batch_size}_optimizer_{optimizer}\"\n",
        "    experiment_path = base_dir / experiment_name\n",
        "    experiment_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    wandb.init(\n",
        "        project=\"electrical-substation-detection\",\n",
        "        entity=\"dar-ta\",\n",
        "        name=f\"yolov10{version}-{experiment_name}\",\n",
        "        config={\n",
        "            \"epochs\": epoch,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"optimizer\": optimizer,\n",
        "            \"version\": version\n",
        "        },\n",
        "        settings=wandb.Settings(init_timeout=300),\n",
        "        dir=str(experiment_path)\n",
        "    )\n",
        "\n",
        "    model = YOLO(f\"yolov10{version}.pt\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    model.train(\n",
        "        data=f\"{dataset_location}/data.yaml\",\n",
        "        epochs=epoch,\n",
        "        batch=batch_size,\n",
        "        optimizer=optimizer,\n",
        "        weight_decay=0.0005,\n",
        "        warmup_epochs=3,\n",
        "        save_dir=str(experiment_path),\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run Grid Search for Multiple Experiments\n",
        "\n",
        "We perform a grid search over various hyperparameters to find the best configuration for our YOLOv10 model. This includes different versions, epochs, batch sizes, and optimizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_location = str(DATASETS_PATH / \"subtantion-monitoring-1\")\n",
        "versions = [\"n\", \"s\", \"m\", \"l\", \"x\"]\n",
        "epochs = [50, 100,150, 200]\n",
        "batch_sizes = [2, 4, 8, 16]\n",
        "optimizers = [\"Adam\", \"SGD\"]\n",
        "\n",
        "for version in versions:\n",
        "    for epoch in epochs:\n",
        "        for batch_size in batch_sizes:\n",
        "            for optimizer in optimizers:\n",
        "                train_yolo_with_wandb(version, epoch, batch_size, optimizer, dataset_location)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": { "name": "python", "version": "3.10" }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
